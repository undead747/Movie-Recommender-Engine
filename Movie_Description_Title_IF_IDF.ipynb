{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Movies Imformation - Retrieval  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Librarys"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "import nltk\n",
    "import os\n",
    "import string\n",
    "import numpy as np\n",
    "import copy\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import re\n",
    "import math\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.stem import PorterStemmer\n",
    "from collections import Counter\n",
    "from num2words import num2words\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "# Lemmatize with POS Tag\n",
    "from nltk.corpus import wordnet\n",
    "from num2words import num2words\n",
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "title = \"stories\"\n",
    "alpha = 0.4"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import DataSet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd = pd.read_csv('../the-movies-dataset/movies_metadata_equal_ratings.csv')\n",
    "smd['description'] = smd['description'].fillna('')\n",
    "smd['title'] = smd['title'].fillna('')\n",
    "N = len(smd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adult</th>\n",
       "      <th>belongs_to_collection</th>\n",
       "      <th>budget</th>\n",
       "      <th>genres</th>\n",
       "      <th>homepage</th>\n",
       "      <th>id</th>\n",
       "      <th>imdb_id</th>\n",
       "      <th>original_language</th>\n",
       "      <th>original_title</th>\n",
       "      <th>overview</th>\n",
       "      <th>...</th>\n",
       "      <th>runtime</th>\n",
       "      <th>spoken_languages</th>\n",
       "      <th>status</th>\n",
       "      <th>tagline</th>\n",
       "      <th>title</th>\n",
       "      <th>video</th>\n",
       "      <th>vote_average</th>\n",
       "      <th>vote_count</th>\n",
       "      <th>description</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 10194, 'name': 'Toy Story Collection', ...</td>\n",
       "      <td>30000000</td>\n",
       "      <td>['Animation', 'Comedy', 'Family']</td>\n",
       "      <td>http://toystory.disney.com/toy-story</td>\n",
       "      <td>862</td>\n",
       "      <td>tt0114709</td>\n",
       "      <td>en</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>81.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Toy Story</td>\n",
       "      <td>False</td>\n",
       "      <td>7.7</td>\n",
       "      <td>5415.0</td>\n",
       "      <td>Led by Woody, Andy's toys live happily in his ...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>65000000</td>\n",
       "      <td>['Adventure', 'Fantasy', 'Family']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8844</td>\n",
       "      <td>tt0113497</td>\n",
       "      <td>en</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>...</td>\n",
       "      <td>104.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}, {'iso...</td>\n",
       "      <td>Released</td>\n",
       "      <td>Roll the dice and unleash the excitement!</td>\n",
       "      <td>Jumanji</td>\n",
       "      <td>False</td>\n",
       "      <td>6.9</td>\n",
       "      <td>2413.0</td>\n",
       "      <td>When siblings Judy and Peter discover an encha...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 119050, 'name': 'Grumpy Old Men Collect...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Romance', 'Comedy']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15602</td>\n",
       "      <td>tt0113228</td>\n",
       "      <td>en</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>...</td>\n",
       "      <td>101.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Still Yelling. Still Fighting. Still Ready for...</td>\n",
       "      <td>Grumpier Old Men</td>\n",
       "      <td>False</td>\n",
       "      <td>6.5</td>\n",
       "      <td>92.0</td>\n",
       "      <td>A family wedding reignites the ancient feud be...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>16000000</td>\n",
       "      <td>['Comedy', 'Drama', 'Romance']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>31357</td>\n",
       "      <td>tt0114885</td>\n",
       "      <td>en</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>...</td>\n",
       "      <td>127.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Friends are the people who let you be yourself...</td>\n",
       "      <td>Waiting to Exhale</td>\n",
       "      <td>False</td>\n",
       "      <td>6.1</td>\n",
       "      <td>34.0</td>\n",
       "      <td>Cheated on, mistreated and stepped on, the wom...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 96871, 'name': 'Father of the Bride Col...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Comedy']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>11862</td>\n",
       "      <td>tt0113041</td>\n",
       "      <td>en</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>...</td>\n",
       "      <td>106.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Just When His World Is Back To Normal... He's ...</td>\n",
       "      <td>Father of the Bride Part II</td>\n",
       "      <td>False</td>\n",
       "      <td>5.7</td>\n",
       "      <td>173.0</td>\n",
       "      <td>Just when George Banks has recovered from his ...</td>\n",
       "      <td>1995</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9020</td>\n",
       "      <td>False</td>\n",
       "      <td>{'id': 286023, 'name': 'Sharknado Collection',...</td>\n",
       "      <td>0</td>\n",
       "      <td>['Comedy', 'Horror', 'Science Fiction']</td>\n",
       "      <td>http://www.syfy.com/sharknado4</td>\n",
       "      <td>390989</td>\n",
       "      <td>tt4831420</td>\n",
       "      <td>en</td>\n",
       "      <td>Sharknado 4: The 4th Awakens</td>\n",
       "      <td>The new installment of the Sharknado franchise...</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>What happens in Vegas, stays in Vegas. Unless ...</td>\n",
       "      <td>Sharknado 4: The 4th Awakens</td>\n",
       "      <td>False</td>\n",
       "      <td>4.3</td>\n",
       "      <td>88.0</td>\n",
       "      <td>The new installment of the Sharknado franchise...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9021</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>8000000</td>\n",
       "      <td>['Drama']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>159550</td>\n",
       "      <td>tt0255313</td>\n",
       "      <td>en</td>\n",
       "      <td>The Last Brickmaker in America</td>\n",
       "      <td>A man must cope with the loss of his wife and ...</td>\n",
       "      <td>...</td>\n",
       "      <td>85.0</td>\n",
       "      <td>[]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>The Last Brickmaker in America</td>\n",
       "      <td>False</td>\n",
       "      <td>7.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>A man must cope with the loss of his wife and ...</td>\n",
       "      <td>2001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9022</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>1000000</td>\n",
       "      <td>['Thriller', 'Romance']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>392572</td>\n",
       "      <td>tt5165344</td>\n",
       "      <td>hi</td>\n",
       "      <td>रुस्तम</td>\n",
       "      <td>Rustom Pavri, an honourable officer of the Ind...</td>\n",
       "      <td>...</td>\n",
       "      <td>150.0</td>\n",
       "      <td>[{'iso_639_1': 'hi', 'name': 'हिन्दी'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>Decorated Officer. Devoted Family Man. Defendi...</td>\n",
       "      <td>Rustom</td>\n",
       "      <td>False</td>\n",
       "      <td>7.3</td>\n",
       "      <td>25.0</td>\n",
       "      <td>Rustom Pavri, an honourable officer of the Ind...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9023</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>15050000</td>\n",
       "      <td>['Adventure', 'Drama', 'History', 'Romance']</td>\n",
       "      <td>NaN</td>\n",
       "      <td>402672</td>\n",
       "      <td>tt3859980</td>\n",
       "      <td>hi</td>\n",
       "      <td>Mohenjo Daro</td>\n",
       "      <td>Village lad Sarman is drawn to big, bad Mohenj...</td>\n",
       "      <td>...</td>\n",
       "      <td>155.0</td>\n",
       "      <td>[{'iso_639_1': 'hi', 'name': 'हिन्दी'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Mohenjo Daro</td>\n",
       "      <td>False</td>\n",
       "      <td>6.7</td>\n",
       "      <td>26.0</td>\n",
       "      <td>Village lad Sarman is drawn to big, bad Mohenj...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9024</td>\n",
       "      <td>False</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "      <td>['Documentary', 'Music']</td>\n",
       "      <td>http://www.thebeatlesliveproject.com/</td>\n",
       "      <td>391698</td>\n",
       "      <td>tt2531318</td>\n",
       "      <td>en</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>The band stormed Europe in 1963, and, in 1964,...</td>\n",
       "      <td>...</td>\n",
       "      <td>99.0</td>\n",
       "      <td>[{'iso_639_1': 'en', 'name': 'English'}]</td>\n",
       "      <td>Released</td>\n",
       "      <td>The band you know. The story you don't.</td>\n",
       "      <td>The Beatles: Eight Days a Week - The Touring Y...</td>\n",
       "      <td>False</td>\n",
       "      <td>7.6</td>\n",
       "      <td>92.0</td>\n",
       "      <td>The band stormed Europe in 1963, and, in 1964,...</td>\n",
       "      <td>2016</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>9025 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      adult                              belongs_to_collection    budget  \\\n",
       "0     False  {'id': 10194, 'name': 'Toy Story Collection', ...  30000000   \n",
       "1     False                                                NaN  65000000   \n",
       "2     False  {'id': 119050, 'name': 'Grumpy Old Men Collect...         0   \n",
       "3     False                                                NaN  16000000   \n",
       "4     False  {'id': 96871, 'name': 'Father of the Bride Col...         0   \n",
       "...     ...                                                ...       ...   \n",
       "9020  False  {'id': 286023, 'name': 'Sharknado Collection',...         0   \n",
       "9021  False                                                NaN   8000000   \n",
       "9022  False                                                NaN   1000000   \n",
       "9023  False                                                NaN  15050000   \n",
       "9024  False                                                NaN         0   \n",
       "\n",
       "                                            genres  \\\n",
       "0                ['Animation', 'Comedy', 'Family']   \n",
       "1               ['Adventure', 'Fantasy', 'Family']   \n",
       "2                            ['Romance', 'Comedy']   \n",
       "3                   ['Comedy', 'Drama', 'Romance']   \n",
       "4                                       ['Comedy']   \n",
       "...                                            ...   \n",
       "9020       ['Comedy', 'Horror', 'Science Fiction']   \n",
       "9021                                     ['Drama']   \n",
       "9022                       ['Thriller', 'Romance']   \n",
       "9023  ['Adventure', 'Drama', 'History', 'Romance']   \n",
       "9024                      ['Documentary', 'Music']   \n",
       "\n",
       "                                   homepage      id    imdb_id  \\\n",
       "0      http://toystory.disney.com/toy-story     862  tt0114709   \n",
       "1                                       NaN    8844  tt0113497   \n",
       "2                                       NaN   15602  tt0113228   \n",
       "3                                       NaN   31357  tt0114885   \n",
       "4                                       NaN   11862  tt0113041   \n",
       "...                                     ...     ...        ...   \n",
       "9020         http://www.syfy.com/sharknado4  390989  tt4831420   \n",
       "9021                                    NaN  159550  tt0255313   \n",
       "9022                                    NaN  392572  tt5165344   \n",
       "9023                                    NaN  402672  tt3859980   \n",
       "9024  http://www.thebeatlesliveproject.com/  391698  tt2531318   \n",
       "\n",
       "     original_language                                     original_title  \\\n",
       "0                   en                                          Toy Story   \n",
       "1                   en                                            Jumanji   \n",
       "2                   en                                   Grumpier Old Men   \n",
       "3                   en                                  Waiting to Exhale   \n",
       "4                   en                        Father of the Bride Part II   \n",
       "...                ...                                                ...   \n",
       "9020                en                       Sharknado 4: The 4th Awakens   \n",
       "9021                en                     The Last Brickmaker in America   \n",
       "9022                hi                                             रुस्तम   \n",
       "9023                hi                                       Mohenjo Daro   \n",
       "9024                en  The Beatles: Eight Days a Week - The Touring Y...   \n",
       "\n",
       "                                               overview  ...  runtime  \\\n",
       "0     Led by Woody, Andy's toys live happily in his ...  ...     81.0   \n",
       "1     When siblings Judy and Peter discover an encha...  ...    104.0   \n",
       "2     A family wedding reignites the ancient feud be...  ...    101.0   \n",
       "3     Cheated on, mistreated and stepped on, the wom...  ...    127.0   \n",
       "4     Just when George Banks has recovered from his ...  ...    106.0   \n",
       "...                                                 ...  ...      ...   \n",
       "9020  The new installment of the Sharknado franchise...  ...     85.0   \n",
       "9021  A man must cope with the loss of his wife and ...  ...     85.0   \n",
       "9022  Rustom Pavri, an honourable officer of the Ind...  ...    150.0   \n",
       "9023  Village lad Sarman is drawn to big, bad Mohenj...  ...    155.0   \n",
       "9024  The band stormed Europe in 1963, and, in 1964,...  ...     99.0   \n",
       "\n",
       "                                       spoken_languages    status  \\\n",
       "0              [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "1     [{'iso_639_1': 'en', 'name': 'English'}, {'iso...  Released   \n",
       "2              [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "3              [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "4              [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "...                                                 ...       ...   \n",
       "9020           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "9021                                                 []  Released   \n",
       "9022            [{'iso_639_1': 'hi', 'name': 'हिन्दी'}]  Released   \n",
       "9023            [{'iso_639_1': 'hi', 'name': 'हिन्दी'}]  Released   \n",
       "9024           [{'iso_639_1': 'en', 'name': 'English'}]  Released   \n",
       "\n",
       "                                                tagline  \\\n",
       "0                                                   NaN   \n",
       "1             Roll the dice and unleash the excitement!   \n",
       "2     Still Yelling. Still Fighting. Still Ready for...   \n",
       "3     Friends are the people who let you be yourself...   \n",
       "4     Just When His World Is Back To Normal... He's ...   \n",
       "...                                                 ...   \n",
       "9020  What happens in Vegas, stays in Vegas. Unless ...   \n",
       "9021                                                NaN   \n",
       "9022  Decorated Officer. Devoted Family Man. Defendi...   \n",
       "9023                                                NaN   \n",
       "9024            The band you know. The story you don't.   \n",
       "\n",
       "                                                  title  video  vote_average  \\\n",
       "0                                             Toy Story  False           7.7   \n",
       "1                                               Jumanji  False           6.9   \n",
       "2                                      Grumpier Old Men  False           6.5   \n",
       "3                                     Waiting to Exhale  False           6.1   \n",
       "4                           Father of the Bride Part II  False           5.7   \n",
       "...                                                 ...    ...           ...   \n",
       "9020                       Sharknado 4: The 4th Awakens  False           4.3   \n",
       "9021                     The Last Brickmaker in America  False           7.0   \n",
       "9022                                             Rustom  False           7.3   \n",
       "9023                                       Mohenjo Daro  False           6.7   \n",
       "9024  The Beatles: Eight Days a Week - The Touring Y...  False           7.6   \n",
       "\n",
       "     vote_count                                        description  year  \n",
       "0        5415.0  Led by Woody, Andy's toys live happily in his ...  1995  \n",
       "1        2413.0  When siblings Judy and Peter discover an encha...  1995  \n",
       "2          92.0  A family wedding reignites the ancient feud be...  1995  \n",
       "3          34.0  Cheated on, mistreated and stepped on, the wom...  1995  \n",
       "4         173.0  Just when George Banks has recovered from his ...  1995  \n",
       "...         ...                                                ...   ...  \n",
       "9020       88.0  The new installment of the Sharknado franchise...  2016  \n",
       "9021        1.0  A man must cope with the loss of his wife and ...  2001  \n",
       "9022       25.0  Rustom Pavri, an honourable officer of the Ind...  2016  \n",
       "9023       26.0  Village lad Sarman is drawn to big, bad Mohenj...  2016  \n",
       "9024       92.0  The band stormed Europe in 1963, and, in 1964,...  2016  \n",
       "\n",
       "[9025 rows x 26 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lowercase"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_lower_case(data):\n",
    "    return np.char.lower(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Stop words are the most commonly occurring words which don’t give any\n",
    "# additional value to the document vector. in-fact removing these will\n",
    "# increase computation and space efficiency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', \"you're\", \"you've\", \"you'll\", \"you'd\", 'your', 'yours', 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', \"she's\", 'her', 'hers', 'herself', 'it', \"it's\", 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves', 'what', 'which', 'who', 'whom', 'this', 'that', \"that'll\", 'these', 'those', 'am', 'is', 'are', 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does', 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until', 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into', 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down', 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here', 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', \"don't\", 'should', \"should've\", 'now', 'd', 'll', 'm', 'o', 're', 've', 'y', 'ain', 'aren', \"aren't\", 'couldn', \"couldn't\", 'didn', \"didn't\", 'doesn', \"doesn't\", 'hadn', \"hadn't\", 'hasn', \"hasn't\", 'haven', \"haven't\", 'isn', \"isn't\", 'ma', 'mightn', \"mightn't\", 'mustn', \"mustn't\", 'needn', \"needn't\", 'shan', \"shan't\", 'shouldn', \"shouldn't\", 'wasn', \"wasn't\", 'weren', \"weren't\", 'won', \"won't\", 'wouldn', \"wouldn't\"]\n"
     ]
    }
   ],
   "source": [
    "print(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_stop_words(data):\n",
    "    new_text = \"\"\n",
    "    stop_words = stopwords.words('english')\n",
    "    words = word_tokenize(str(data))\n",
    "\n",
    "    for word in words:\n",
    "        if word not in stop_words and len(word) > 1:\n",
    "            new_text = new_text + \" \" + word\n",
    "        \n",
    "    return new_text        "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# (Punctuation - dấu chấm câu)are the unnecessary symbols that are in\n",
    "# our corpus documents, we should be little careful with what we are \n",
    "# doing with this. There might be few problems such as U.S — us \n",
    "# “United Stated” being converted to “us” after the preprocessing. \n",
    "# hyphen and should usually be dealt little carefully. but for this \n",
    "# problem statement we are just going to remove these"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_punctuation(data):\n",
    "    symbols = \"!\\\"#$%&()*+-./:;<=>?@[\\]^_`{|}~\\n\"\n",
    "    for i in range(len(symbols)):\n",
    "        data = np.char.replace(data, symbols[i], ' ')\n",
    "        data = np.char.replace(data, \"  \", \" \")\n",
    "    data = np.char.replace(data, ',', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_apostrophe(data):\n",
    "    return np.char.replace(data, \"'\", \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Steamming"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(data):\n",
    "    new_text = \"\"\n",
    "    words = word_tokenize(str(data))\n",
    "    stemmer = PorterStemmer()\n",
    "    \n",
    "    for word in words:\n",
    "        new_text = new_text + \" \" + stemmer.stem(word)\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' the stripe bat are hang on their feet for best'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"The striped bats are hanging on their feet for best\"\n",
    "stemming(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemmatizer words"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Get word pos "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'JJ'), ('play', 'VBP'), ('so', 'RB'), ('well', 'RB')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"i play so well\"\n",
    "nltk.pos_tag(s.split())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('i', 'JJ'), ('play', 'VBP'), ('game', 'NN')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s = \"i play game\"\n",
    "nltk.pos_tag(word_tokenize(s))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_wordnet_pos(word):\n",
    "\n",
    "    tag = nltk.pos_tag([word])[0][1][0].upper()\n",
    "    \n",
    "    tag_dict = {\"J\": wordnet.ADJ,\n",
    "                \"N\": wordnet.NOUN,\n",
    "                \"V\": wordnet.VERB,\n",
    "                \"R\": wordnet.ADV}\n",
    "\n",
    "    return tag_dict.get(tag, wordnet.NOUN)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatizer words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lemmatizer_words(data):\n",
    "    new_text = \"\"\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = word_tokenize(str(data))\n",
    "   \n",
    "    lemmatizer_text = [lemmatizer.lemmatize(w, get_wordnet_pos(w)) for w in words]\n",
    "\n",
    "    for word in lemmatizer_text:\n",
    "        new_text = new_text + \" \" + word\n",
    "    return  new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' The strip bat be hang on their foot for best'"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"The striped bats are hanging on their feet for best\"\n",
    "data\n",
    "lemmatizer_words(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Convert Number "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_numbers(data):\n",
    "    tokens = word_tokenize(str(data))\n",
    "    new_text = \"\"\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            w = num2words(int(w))\n",
    "        except:\n",
    "            a = 0\n",
    "        new_text = new_text + \" \" + w\n",
    "    new_text = np.char.replace(new_text, \"-\", \" \")\n",
    "    return new_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(' one hundred and twenty three', dtype='<U29')"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = \"123\"\n",
    "convert_numbers(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Combine all Preprocess step"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    data = convert_lower_case(data)\n",
    "    data = remove_punctuation(data) #remove comma seperately\n",
    "    data = remove_stop_words(data)\n",
    "    data = remove_apostrophe(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = lemmatizer_words(data)\n",
    "    data = stemming(data)\n",
    "    \n",
    "    data = remove_punctuation(data)\n",
    "    data = convert_numbers(data)\n",
    "    data = lemmatizer_words(data)\n",
    "    data = stemming(data) #needed again as we need to stem the words\n",
    "    data = remove_punctuation(data) #needed again as num2word is giving few hypens and commas fourty-one\n",
    "    data = remove_stop_words(data) #needed again as num2word is giving stop words 101 - one hundred and one\n",
    "    return data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word tokenize data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       Led by Woody, Andy's toys live happily in his ...\n",
       "1       When siblings Judy and Peter discover an encha...\n",
       "2       A family wedding reignites the ancient feud be...\n",
       "3       Cheated on, mistreated and stepped on, the wom...\n",
       "4       Just when George Banks has recovered from his ...\n",
       "                              ...                        \n",
       "9020    The new installment of the Sharknado franchise...\n",
       "9021    A man must cope with the loss of his wife and ...\n",
       "9022    Rustom Pavri, an honourable officer of the Ind...\n",
       "9023    Village lad Sarman is drawn to big, bad Mohenj...\n",
       "9024    The band stormed Europe in 1963, and, in 1964,...\n",
       "Name: description, Length: 9025, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "smd['description']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "processed_text = []\n",
    "processed_title = []\n",
    "\n",
    "for index, row in smd.iterrows():\n",
    "    description = row['description']\n",
    "    title = row['title']   \n",
    "    \n",
    "    processed_text.append(word_tokenize(str(preprocess(description))))\n",
    "    processed_title.append(word_tokenize(str(preprocess(title))))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['lead',\n",
       "  'woodi',\n",
       "  'andi',\n",
       "  'toy',\n",
       "  'live',\n",
       "  'happili',\n",
       "  'room',\n",
       "  'andi',\n",
       "  'birthday',\n",
       "  'bring',\n",
       "  'buzz',\n",
       "  'lightyear',\n",
       "  'onto',\n",
       "  'scene',\n",
       "  'afraid',\n",
       "  'lose',\n",
       "  'place',\n",
       "  'andi',\n",
       "  'heart',\n",
       "  'woodi',\n",
       "  'plot',\n",
       "  'buzz',\n",
       "  'circumst',\n",
       "  'separ',\n",
       "  'buzz',\n",
       "  'woodi',\n",
       "  'owner',\n",
       "  'duo',\n",
       "  'eventu',\n",
       "  'learn',\n",
       "  'put',\n",
       "  'asid',\n",
       "  'differ']]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_text[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['toy', 'stori'],\n",
       " ['jumanji'],\n",
       " ['grumpier', 'old', 'men'],\n",
       " ['wait', 'exhal'],\n",
       " ['father', 'bride', 'part', 'ii'],\n",
       " ['heat'],\n",
       " ['sabrina'],\n",
       " ['tom', 'huck'],\n",
       " ['sudden', 'death'],\n",
       " ['goldeney']]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_title[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "smd = smd.reset_index()\n",
    "titles = smd['title']\n",
    "indices = pd.Series(smd.index, index=smd['title'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Corpus Bag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mục đích là để tạo ra một bộ từ điển liệt kê tất cả các các từ và danh sách các bộ phim có sự xuất hiện của nó \n",
    "\n",
    "\n",
    "DF = {}\n",
    "\n",
    "for i in range(N):\n",
    "    tokens = processed_text[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i} #Trừ khi trong DF[w] có tồn tại i\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    for w in tokens:\n",
    "        try:\n",
    "            DF[w].add(i)\n",
    "        except:\n",
    "            DF[w] = {i}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tính tần xuất xuất hiện của từ đó trên toàn bộ danh sách bộ phim \n",
    "for i in DF:\n",
    "    DF[i] = len(DF[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "22336"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab_size = len(DF)\n",
    "total_vocab_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['lead',\n",
       " 'woodi',\n",
       " 'andi',\n",
       " 'toy',\n",
       " 'live',\n",
       " 'happili',\n",
       " 'room',\n",
       " 'birthday',\n",
       " 'bring',\n",
       " 'buzz']"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_vocab = [x for x in DF]\n",
    "total_vocab[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def doc_freq(word):\n",
    "    c = 0\n",
    "    try:\n",
    "        c = DF[word]\n",
    "    except:\n",
    "        pass\n",
    "    return c"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Calcualte DF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcalate DF-IDF from description"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3321095381255287"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc  = 0\n",
    "tf_idf = {}\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_text[i]\n",
    "    \n",
    "    # counting frequence the number of word in a document\n",
    "    counter = Counter(tokens + processed_title[i])\n",
    "    words_count = len(tokens + processed_title[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log((N)/(df + 1))\n",
    "        \n",
    "        tf_idf[doc, token] = tf*idf\n",
    "    \n",
    "    doc += 1\n",
    "    \n",
    "tf_idf[(0,\"toy\")]    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Calcalate DF-IDF from title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3321095381255287"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf_idf_title = {}\n",
    "doc = 0\n",
    "\n",
    "for i in range(N):\n",
    "    \n",
    "    tokens = processed_title[i]\n",
    "    counter = Counter(tokens + processed_text[i])\n",
    "    words_count = len (tokens + processed_text[i])\n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = np.log(N/(df + 1))\n",
    "        \n",
    "        tf_idf_title[doc, token] = tf*idf\n",
    "    doc += 1 \n",
    "    \n",
    "tf_idf_title[(0,\"toy\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Merging the TF-IDF according to weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "#TF-IDF(document) = TF-IDF(body) * alpha + TF-IDF(title) * (1-alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tf_idf:\n",
    "    tf_idf[i] *= alpha\n",
    "\n",
    "for i in tf_idf_title:\n",
    "    tf_idf_title[i] *= (1 - alpha)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "# shitty code\n",
    "# thực ra nó lặp trên tf_idf nếu thằng nào mà có mặt trên cả title và body thì if_idf của nó tính bằng body và\n",
    "# title đều như nhau.\n",
    "# nếu 1 thằng word nào đó mà không có mặt trên tf_idf_title thì tf_idf_title[i] không tồn tại => safe, nó sẽ có \n",
    "# giá trị bằng tf_idf trên body nhân với alpha"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.3321095381255287"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "for i in tf_idf_title:\n",
    "    if i in tf_idf: tf_idf[i] = tf_idf[i] + tf_idf_title[i]\n",
    "    else : tf_idf[i] = tf_idf_title[i]\n",
    "\n",
    "tf_idf[(0,\"toy\")]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Mathching score method "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching score with query string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ý tưởng của mathching score là tìm tất cả các ký tự giống nhau giữa từng đoạn văn bản và query rồi tính tổng\n",
    "# giá trị của các ký tự đó (đối với mỗi đoạn văn bản một) rồi lập list xếp theo giá trị query_weights\n",
    "\n",
    "def matching_score(query):\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"Matching score\")\n",
    "    print(\"\\n Query:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    query_weights = {}\n",
    "    \n",
    "    for key in tf_idf:\n",
    "        if key[1] in tokens:\n",
    "            try: \n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "    \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse =True)\n",
    "    \n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    \n",
    "    for i in query_weights[:10]:\n",
    "         print(smd.iloc[i[0]]['title']) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Matching score\n",
      "\n",
      " Query: the mafia god father \n",
      "\n",
      "['mafia', 'god', 'father']\n",
      "\n",
      "Jane Austen's Mafia!\n",
      "Dear God\n",
      "Oh, God!\n",
      "How I Killed My Father\n",
      "Fathers' Day\n",
      "Dragon Ball Z: Battle of Gods\n",
      "The Lawnmower Man\n",
      "Black God, White Devil\n",
      "In the Name of the Father\n",
      "Father of the Bride\n"
     ]
    }
   ],
   "source": [
    "matching_score(\"the mafia god father \")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Matching Score with movie tf_idf value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_movie_query(title):\n",
    "    idx = indices[title]\n",
    "    tokens = []\n",
    "    \n",
    "    for i in tf_idf:\n",
    "        if i[0] == idx: tokens.append(i[1])\n",
    "    \n",
    "    return tokens "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def matching_score_ver1(title):\n",
    "    tokens = get_movie_query(title)\n",
    "    \n",
    "    query_weights = {}\n",
    "    \n",
    "    for key in tf_idf:\n",
    "        if key[1] in tokens:\n",
    "            try:\n",
    "                query_weights[key[0]] += tf_idf[key]\n",
    "            except:\n",
    "                query_weights[key[0]] = tf_idf[key]\n",
    "   \n",
    "    query_weights = sorted(query_weights.items(), key=lambda x: x[1], reverse = True)\n",
    "    # x[1] is matching score value\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    for i in query_weights[1:10]:\n",
    "        print(smd.iloc[i[0]]['title'])\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The Dark Knight Rises\n",
      "Batman: The Dark Knight Returns, Part 2\n",
      "Henry's Crime\n",
      "Citizen's Band\n",
      "Batman\n",
      "Batman Returns\n",
      "Batman: Under the Red Hood\n",
      "Batman Begins\n",
      "Batman: Mask of the Phantasm\n"
     ]
    }
   ],
   "source": [
    "matching_score_ver1(\"The Dark Knight\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF Cosine Similarity Ranking"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hàm tính đố tương đồng giữa 2 vector \n",
    "def cosine_sim_calculate(a,b):\n",
    "    cos_sim = np.dot(a,b)/(np.linalg.norm(a)*np.linalg.norm(b))\n",
    "    return cos_sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Vectorizing tf-idf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# lập danh sách các vector \n",
    "# ma trận D ban đầu có giá trị toàn bằng 0, sau đó chúng ta sẽ duyệt tf_idf và trám các giá trị có tồn tại vào D\n",
    "D = np.zeros((N, total_vocab_size))\n",
    "for i in tf_idf:\n",
    "    try:\n",
    "        ind = total_vocab.index(i[1]) # vị trí của từ trong vocabolary \n",
    "        D[i[0]][ind] = tf_idf[i] \n",
    "    except:\n",
    "            pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tạo vector từ query, nếu từ nào không xuất hiện thì tần suất xuất hiện của nó bằng 0\n",
    "def gen_vector(tokens):\n",
    "    \n",
    "    Q = np.zeros(total_vocab_size)\n",
    "    \n",
    "    counter = Counter(tokens)\n",
    "    words_count = len(tokens)\n",
    "    \n",
    "    \n",
    "    for token in np.unique(tokens):\n",
    "        tf = counter[token]/words_count\n",
    "        df = doc_freq(token)\n",
    "        idf = math.log(N/(df + 1))\n",
    "        \n",
    "        try:\n",
    "            ind = total_vocab.index(token)\n",
    "            Q[ind] = tf*idf\n",
    "        except:\n",
    "            pass\n",
    "    \n",
    "    return Q"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity with query string "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "#query = \"Dark night\"\n",
    "\n",
    "#preprocessed_query = preprocess(query)\n",
    "#tokens = word_tokenize(str(preprocessed_query))\n",
    "#array =  gen_vector(tokens)\n",
    "\n",
    "#for i in array: \n",
    "#    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(k, query):\n",
    "    print(\"Cosine Similarity\")\n",
    "    preprocessed_query = preprocess(query)\n",
    "    tokens = word_tokenize(str(preprocessed_query))\n",
    "    \n",
    "    print(\"\\n Query:\", query)\n",
    "    print(\"\")\n",
    "    print(tokens)\n",
    "    \n",
    "    d_cosines = []\n",
    "    \n",
    "    query_vector = gen_vector(tokens)\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim_calculate(query_vector, d))\n",
    "    \n",
    "    out = np.array(d_cosines).argsort()[-k:][::-1]\n",
    "    \n",
    "    print(\"\")\n",
    "    \n",
    "    for i in out:\n",
    "       print(smd.iloc[i]['title']) \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      " Query: The Dark Knight\n",
      "\n",
      "['dark', 'knight']\n",
      "\n",
      "Last Knights\n",
      "The Dark Knight Rises\n",
      "The Hollywood Knights\n",
      "A Knight's Tale\n",
      "The Seeker: The Dark Is Rising\n",
      "Dark Water\n",
      "The Dark Knight\n",
      "Dark Water\n",
      "Black Knight\n",
      "A Shot in the Dark\n"
     ]
    }
   ],
   "source": [
    "cosine_similarity(10, \"The Dark Knight\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cosine Similarity\n",
      "\n",
      " Query: The Godfather\n",
      "\n",
      "['godfath']\n",
      "\n",
      "The Godfather: Part III\n",
      "Tokyo Godfathers\n",
      "The Godfather\n",
      "Bright Eyes\n",
      "The Godfather: Part II\n",
      "Things to Do in Denver When You're Dead\n",
      "Jane Austen's Mafia!\n",
      "Free Enterprise\n",
      "The Freshman\n",
      "Cinderfella\n"
     ]
    }
   ],
   "source": [
    "Q = cosine_similarity(10, \"The Godfather\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Cosine similarity with Movie vector "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gen corpus matrix vector using  sklearn.linear_kernel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cosine_sim = linear_kernel(D, D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.31099556, 0.00285685, 0.        , ..., 0.        , 0.        ,\n",
       "       0.00087735])"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cosine_sim[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gen corpus matrix vector from scatch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity_ver2(k,title):\n",
    "    idx = indices[title]\n",
    "    d_cosines = []\n",
    "    \n",
    "    for d in D:\n",
    "        d_cosines.append(cosine_sim_calculate(D[idx],d))\n",
    "    \n",
    "    out = np.array(d_cosines).argsort()[::-1]\n",
    "    \n",
    "    return out[1:k]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = cosine_similarity_ver2(11,\"The Dark Knight\")\n",
    "#smd.iloc[result].title"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "f = open('Store_Description_contentBased.pckl', 'wb')\n",
    "pickle.dump([tf_idf,indices], f)\n",
    "\n",
    "f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('tf_idf_vector_matrix.npy', D)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
